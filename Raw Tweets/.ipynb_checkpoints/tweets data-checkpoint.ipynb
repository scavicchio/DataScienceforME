{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GetOldTweets3 as got\n",
    "import pandas as pd\n",
    "from itertools import compress \n",
    "from datetime import timedelta, date\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "pool = multiprocessing.Pool(num_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get tweets data using API text_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input query topics, number of counts to see, date of tweets(every other day from 2020-1-1 to 2020-4-25)\n",
    "def text_query_to_csv(text_query, count, since_until):\n",
    "    \n",
    "    # Creation of query object (get )\n",
    "    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(text_query).setSince(since_until[0]).setUntil(since_until[1]).setMaxTweets(count).setTopTweets(True)\n",
    "   \n",
    "    # Creation of list that contains all tweets\n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "    \n",
    "    # Creating list of chosen tweet data (tweets date, tweets text, user sent the tweets, retweets number)\n",
    "    text_tweets = [[tweet.date, tweet.text, tweet.username, tweet.retweets] for tweet in tweets]\n",
    "    \n",
    "    # Creation of dataframe from tweets\n",
    "    tweets_df = pd.DataFrame(text_tweets, columns = ['Datetime', 'Text','user','retweets'])\n",
    "    \n",
    "    return tweets_df\n",
    "    \n",
    "    # Converting tweets dataframe to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input query topics, number of counts to see, date of tweets(every other day from 2020-1-1 to 2020-4-25)\n",
    "def popular_to_csv(count, since_until):\n",
    "    # Creation of query object (get )\n",
    "    query = ' '\n",
    "    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(query).setSince(since_until[0]).setUntil(since_until[1]).setMaxTweets(count).setTopTweets(True)\n",
    "    # Creation of list that contains all tweets\n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "    # Creating list of chosen tweet data (tweets date, tweets text, user sent the tweets, retweets number)\n",
    "    text_tweets = [[tweet.date, tweet.text, tweet.username, tweet.retweets] for tweet in tweets]\n",
    "    # Creation of dataframe from tweets\n",
    "    tweets_df = pd.DataFrame(text_tweets, columns = ['Datetime', 'Text','user','retweets'])\n",
    "    return tweets_df\n",
    "    \n",
    "    # Converting tweets dataframe to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input query topics, number of counts to see, date of tweets(every other day from 2020-1-1 to 2020-4-25)\n",
    "def text_location_query_to_csv(text_query, location, within, count, since_until):\n",
    "    \n",
    "    # Creation of query object (get )\n",
    "    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(text_query).setNear(location).setWithin(within).setSince(since_until[0]).setUntil(since_until[1]).setMaxTweets(count).setTopTweets(True)\n",
    "   \n",
    "    # Creation of list that contains all tweets\n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "    \n",
    "    # Creating list of chosen tweet data (tweets date, tweets text, user sent the tweets, retweets number)\n",
    "    text_tweets = [[tweet.date, tweet.text, tweet.username, tweet.retweets] for tweet in tweets]\n",
    "    \n",
    "    # Creation of dataframe from tweets\n",
    "    tweets_df = pd.DataFrame(text_tweets, columns = ['Datetime', 'Text','user','retweets'])\n",
    "    \n",
    "    return tweets_df\n",
    "    \n",
    "    # Converting tweets dataframe to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input query topics, number of counts to see, date of tweets(every other day from 2020-1-1 to 2020-4-25)\n",
    "def popular_location_query_to_csv(location, within, count, since_until):\n",
    "    \n",
    "    # Creation of query object (get )\n",
    "    tweetCriteria = got.manager.TweetCriteria().setNear(location).setWithin(within).setSince(since_until[0]).setUntil(since_until[1]).setMaxTweets(count).setTopTweets(True)\n",
    "   \n",
    "    # Creation of list that contains all tweets\n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "    \n",
    "    # Creating list of chosen tweet data (tweets date, tweets text, user sent the tweets, retweets number)\n",
    "    text_tweets = [[tweet.date, tweet.text, tweet.username, tweet.retweets] for tweet in tweets]\n",
    "    \n",
    "    # Creation of dataframe from tweets\n",
    "    tweets_df = pd.DataFrame(text_tweets, columns = ['Datetime', 'Text','user','retweets'])\n",
    "    \n",
    "    return tweets_df\n",
    "    \n",
    "    # Converting tweets dataframe to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a date loop for the required date range\n",
    "date_loop = []  \n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "start_date = date(2020, 1, 21)\n",
    "end_date = date(2020, 5, 5)\n",
    "for single_date in daterange(start_date, end_date):\n",
    "    date_loop.append(single_date.strftime(\"%Y-%m-%d\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating pairs of date from the date range\n",
    "res = list(zip(date_loop, date_loop[1:] + date_loop[:1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "start_new_thread expected at least 2 arguments, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ccb0fcfcf311>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0m_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_query_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'coronavirus'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnToCollect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: start_new_thread expected at least 2 arguments, got 1"
     ]
    }
   ],
   "source": [
    "# get all popular coronavirus tweets\n",
    "dic1 = []\n",
    "nToCollect = 100\n",
    "for num in range(0,len(res)):\n",
    "    print(num)\n",
    "    dic1.append(text_query_to_csv('coronavirus', nToCollect, res[num]))\n",
    "    \n",
    "df1 = pd.concat(dic1)\n",
    "df1.to_csv('general_covid_tweet_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all popular general tweets in NYC area\n",
    "dic3 = []\n",
    "nToCollect = 100\n",
    "\n",
    "location = \"New York City, New York\"\n",
    "within = \"50km\"\n",
    "for num in range(0,len(res)):\n",
    "    print(num)\n",
    "    dic3.append(popular_location_query_to_csv(location, within, nToCollect, res[num]))\n",
    "    \n",
    "df3 = pd.concat(dic3)\n",
    "df3.to_csv('nyc_popular_tweet_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new dataset for each day's COVID NYC tweets from 1-1 to 4-25\n",
    "# 50 top tweets for each day for about 110 days\n",
    "dic4 = []\n",
    "nToCollect = 100\n",
    "\n",
    "location = \"New York City, New York\"\n",
    "within = \"50km\"\n",
    "for num in range(0,len(res)):\n",
    "    print(num)\n",
    "    dic4.append(text_location_query_to_csv('coronavirus', location, within, nToCollect, res[num]))\n",
    "    \n",
    "df4 = pd.concat(dic4)\n",
    "df4.to_csv('nyc_covid_tweet_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
