{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://programminghistorian.org/en/lessons/sentiment-analysis\n",
    "# https://textblob.readthedocs.io/en/dev/quickstart.html#spelling-correction\n",
    "# https://www.kaggle.com/ssishu/factual-authenticity-analysis-of-tweets\n",
    "# https://medium.com/datadriveninvestor/nlp-with-lda-analyzing-topics-in-the-enron-email-dataset-20326b7ae36f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# just uncomment to download these once\n",
    "#nltk.download('vader_lexicon')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "# going to do initial sentiment using vader\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "senti = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textblob sentiment analysis\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "\n",
    "tweets = pd.read_csv(\"../tweet_data.csv\")\n",
    "\n",
    "df = pd.DataFrame(data=tweets[\"Text\"])\n",
    "df.insert(1,column=\"retweets\",value=tweets[\"retweets\"])\n",
    "# change to string\n",
    "df[\"Text\"] = df['Text'].astype(str)\n",
    "df[\"retweets\"] = df['retweets'].astype(int)\n",
    "\n",
    "polarity = np.zeros(len(df))\n",
    "subjectivity = np.zeros(len(df))\n",
    "\n",
    "for item in range(len(df)):\n",
    "    polarity[item] = TextBlob(df['Text'][item]).sentiment[0]\n",
    "    subjectivity[item] = TextBlob(df['Text'][item]).sentiment[1]\n",
    "    \n",
    "df.insert(2,column=\"polarity\",value=polarity)\n",
    "df.insert(3,column=\"subjectivity\",value=subjectivity)\n",
    "\n",
    "# clean the text data\n",
    "#remove special characters\n",
    "#df['Text'] = df['Text'].str.replace('[^ws]','')\n",
    "#lowercase everything\n",
    "df['Text'] = df['Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "# remove unimportant kinds of words that dont add value\n",
    "unimportant = stopwords.words('english')\n",
    "# not going to do stemming because this is twitter and people mispell things all the time\n",
    "#acutlaly, here we can use textblob to correct the words spelling?\n",
    "\n",
    "df.apply()\n",
    "\n",
    "print(df['Text'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
