{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'trained_sentiment_model.sav'\n",
    "#nb = pickle.load(open(filename, 'rb'))\n",
    "# https://heartbeat.fritz.ai/guide-to-saving-hosting-your-first-machine-learning-model-cdf69729e85d\n",
    "\n",
    "classifier = joblib.load('classifier.pkl')\n",
    "tfidfVectorizer = joblib.load('tfidfVectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen = pd.read_csv(\"../Cleaned Tweets/cleaned_general_covid_tweet_data.csv\")\n",
    "df_nyc_covid = pd.read_csv(\"../Cleaned Tweets/cleaned_nyc_covid_tweet_data.csv\")\n",
    "df_nyc_gen = pd.read_csv(\"../Cleaned Tweets/cleaned_nyc_popular_tweet_data.csv\")\n",
    "\n",
    "df_gen['senti'] = df_gen['retweets'].astype(float)\n",
    "df_nyc_gen['senti'] = df_nyc_gen['retweets'].astype(float)\n",
    "df_nyc_covid['senti'] = df_nyc_covid['retweets'].astype(float)\n",
    "\n",
    "df_gen['sentiSC'] = df_gen['retweets'].astype(float)\n",
    "df_nyc_gen['sentiSC'] = df_nyc_gen['retweets'].astype(float)\n",
    "df_nyc_covid['sentiSC'] = df_nyc_covid['retweets'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# assume it is already cleaned\n",
    "\n",
    "# feed this function an individual text string and it will output either a 0 or 4\n",
    "def sentiScore(text):\n",
    "    corpus = []\n",
    "    corpus.append(text)\n",
    "    x_tfid = tfidfVectorizer.transform(corpus).toarray()\n",
    "    score = classifier.predict(x_tfid)\n",
    "    return score\n",
    "\n",
    "print(\"1\")\n",
    "df_gen['senti'] = df_gen['cleanText'].apply(lambda x : sentiScore(x))\n",
    "print(\"2\")\n",
    "df_nyc_gen['senti'] = df_nyc_gen['cleanText'].apply(lambda x : sentiScore(x))\n",
    "print(\"3\")\n",
    "df_nyc_covid['senti'] = df_nyc_covid['cleanText'].apply(lambda x : sentiScore(x))\n",
    "\n",
    "print(\"1\")\n",
    "df_gen['sentiSC'] = df_gen['spellCorrected'].apply(lambda x : sentiScore(x))\n",
    "print(\"2\")\n",
    "df_nyc_gen['sentiSC'] = df_nyc_gen['spellCorrected'].apply(lambda x : sentiScore(x))\n",
    "print(\"3\")\n",
    "df_nyc_covid['sentiSC'] = df_nyc_covid['spellCorrected'].apply(lambda x : sentiScore(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>retweets</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>spellCorrected</th>\n",
       "      <th>senti</th>\n",
       "      <th>sentiSC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-21 23:59:43+00:00</td>\n",
       "      <td>It would be interesting to see if the Wuhan co...</td>\n",
       "      <td>87</td>\n",
       "      <td>it would interesting see wuhan coronavirus bin...</td>\n",
       "      <td>it would interesting see wuhan coronavirus bin...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-21 23:59:41+00:00</td>\n",
       "      <td>CBP Enacts ‘Enhanced Health Screening’ as Chin...</td>\n",
       "      <td>57</td>\n",
       "      <td>cbp enacts ‘ enhanced health screening ’ chine...</td>\n",
       "      <td>cup enacts a enhanced health screening a chine...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-21 23:59:06+00:00</td>\n",
       "      <td>Chinese coronavirus may have been lurking in a...</td>\n",
       "      <td>23</td>\n",
       "      <td>chinese coronavirus may lurking animal decade</td>\n",
       "      <td>chinese coronavirus may lurking animal decade</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-21 23:58:27+00:00</td>\n",
       "      <td>CDC and WHO are learning more about this new c...</td>\n",
       "      <td>25</td>\n",
       "      <td>cdc who learning new coronavirus every day at ...</td>\n",
       "      <td>cdc who learning new coronavirus every day at ...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-01-21 23:54:52+00:00</td>\n",
       "      <td>My take: China is doing a massive cover up &amp; p...</td>\n",
       "      <td>23</td>\n",
       "      <td>my take china massive cover practicing crimina...</td>\n",
       "      <td>my take china massive cover practicing crimina...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   Datetime  \\\n",
       "0           0  2020-01-21 23:59:43+00:00   \n",
       "1           1  2020-01-21 23:59:41+00:00   \n",
       "2           2  2020-01-21 23:59:06+00:00   \n",
       "3           3  2020-01-21 23:58:27+00:00   \n",
       "4           4  2020-01-21 23:54:52+00:00   \n",
       "\n",
       "                                                Text  retweets  \\\n",
       "0  It would be interesting to see if the Wuhan co...        87   \n",
       "1  CBP Enacts ‘Enhanced Health Screening’ as Chin...        57   \n",
       "2  Chinese coronavirus may have been lurking in a...        23   \n",
       "3  CDC and WHO are learning more about this new c...        25   \n",
       "4  My take: China is doing a massive cover up & p...        23   \n",
       "\n",
       "                                           cleanText  \\\n",
       "0  it would interesting see wuhan coronavirus bin...   \n",
       "1  cbp enacts ‘ enhanced health screening ’ chine...   \n",
       "2     chinese coronavirus may lurking animal decade    \n",
       "3  cdc who learning new coronavirus every day at ...   \n",
       "4  my take china massive cover practicing crimina...   \n",
       "\n",
       "                                      spellCorrected senti sentiSC  \n",
       "0  it would interesting see wuhan coronavirus bin...   [4]     [4]  \n",
       "1  cup enacts a enhanced health screening a chine...   [4]     [4]  \n",
       "2      chinese coronavirus may lurking animal decade   [4]     [4]  \n",
       "3  cdc who learning new coronavirus every day at ...   [4]     [4]  \n",
       "4  my take china massive cover practicing crimina...   [0]     [0]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gen.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.to_csv('senti_general_covid_tweet_data.csv')\n",
    "df_nyc_covid.to_csv('senti_nyc_covid_tweet_data.csv')\n",
    "df_nyc_gen.to_csv('senti_nyc_popular_tweet_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
